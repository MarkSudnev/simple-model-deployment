services:
  frontend:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    environment:
      - OPENAI_API_BASE_URL=http://model-runner.docker.internal/engines/v1
      - WEBUI_NAME=Docker Model Runner
    volumes:
      - openwebui-vol:/app/backend/data
    models:
      - llama_model

models:
  llama_model:
    model: ai/llama3.2:1B-Q8_0
    context_size: 1024

volumes:
  openwebui-vol:
